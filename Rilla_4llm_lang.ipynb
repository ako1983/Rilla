{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install langchain openai chromadb langchainhub\n",
    "\n",
    "# Set env var OPENAI_API_KEY or load from a .env file\n",
    "import dotenv\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "env_path = os.path.join(os.getcwd(), '.env')\n",
    "# Load env vars from .env file\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "#loader = WebBaseLoader(\"https://saychess.substack.com/p/10-simple-pieces-of-chess-advice\")\n",
    "loader= WebBaseLoader('https://www.rillavoice.com/#how-it-works') \n",
    "# Split documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 0)\n",
    "splits = text_splitter.split_documents(loader.load())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Embed and store splits\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "vectorstore = Chroma.from_documents(documents=splits,embedding=OpenAIEmbeddings(openai_api_key=openai.api_key))\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Prompt \n",
    "# https://smith.langchain.com/hub/rlm/rag-prompt\n",
    "\n",
    "from langchain import hub\n",
    "rag_prompt = hub.pull(\"rlm/rag-prompt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LLM\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.1 , openai_api_key=openai.api_key,  )\n",
    "\n",
    "# RAG chain \n",
    "\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()} \n",
    "    | rag_prompt \n",
    "    | llm \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Rillavoice works by capturing conversations from sales representatives' phones or tablets using the Rilla App. It then automatically transcribes and analyzes these conversations using Artificial Intelligence. This allows sales teams to train and improve by analyzing the thousands of conversations they have with customers in the field.\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rag_chain.invoke(\"how does Rillavoice works?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
